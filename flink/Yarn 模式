Yarn 模式

以 Yarn 模式部署 Flink 任务时，要求 Flink 是有 Hadoop 支持的版本，Hadoop环境需要保证版本在 2.2 以上，并且集群中安装有 HDFS 服务

1. 添加Hadoop支持
    Flink 本身只提供支持Hadoop  2.4.1,   2.6.5,    2.7.5,    2.8.3 的预编译安装包。如果想要flink on yarn（3.x）,一定需要自己编译
    将hadoop2.8.3支持包放入flink的lib目录下
    cp flink-shaded-hadoop-2-uber-2.8.3-10.0.jar /opt/module/flink-1.10.1-Standalone/lib
    注：hadoop2.8.3可以支持flink和Hadoop3.x的支持，如果要使用Hadoop3.x的新特性，需要自编译 适配Hadoop3.X版本

2. Flink on Yarn
    Flink 提供了两种在 yarn 上运行的模式，分别为 Session-Cluster 和 Per-Job-Cluster 模式。

    1.Session-Cluster 模式
            Session-Cluster 模式需要先启动集群，然后再提交作业，接着会向 yarn 申请一块空间后，资源永远保持不变。如果资源满了，下一个作业就无法提交，
        只能等到 yarn 中的其中一个作业执行完成后，释放了资源，下个作业才会正常提交。所有作业共享 Dispatcher 和 ResourceManager；共享资源；适合规模
        小执行时间短的作业。
            在 yarn 中初始化一个 flink 集群，开辟指定的资源，以后提交任务都向这里提交。这个 flink 集群会常驻在 yarn 集群中，除非手工停止。

    2.启动 hadoop 集群
    3.启动 yarn-session
        /opt/module/flink-1.10.1-Standalone/bin/yarn-session.sh -n 2 -s 2 -jm 1024 -tm 1024 -nm test -d
        其中：
            -n(--container)：TaskManager 的数量。
            -s(--slots)： 每个 TaskManager 的 slot 数量，默认一个 slot 一个 core，默认每个
            taskmanager 的 slot 的个数为 1，有时可以多一些 taskmanager，做冗余。
            -jm：JobManager 的内存（单位 MB)。
            -tm：每个 taskmanager 的内存（单位 MB)。
            -nm：yarn 的 appName(现在 yarn 的 ui 上的名字)。
            -d：后台执行。
    4.执行任务
        ./flink run -c com.liu.wc.StreamWordCount FlinkTutorial-1.0-SNAPSHOT-jar-with-dependencies.jar --host lcoalhost –port 7777

    5.取消 yarn-session
        yarn application --kill application_1619168524228_0001

    2.Per-Job-Cluster 模式
            一个 Job 会对应一个集群，每提交一个作业会根据自身的情况，都会单独向 yarn 申请资源，直到作业执行完成，一个作业的失败与否并不会影响下一个作业
        的正常提交和运行。独享 Dispatcher 和 ResourceManager，按需接受资源申请；适合规模大长时间运行的作业。
            每次提交都会创建一个新的 flink 集群，任务之间互相独立，互不影响，方便管理。任务执行完成之后创建的集群也会消失。

    2.启动 hadoop 集群
    3.不启动 yarn-session，直接执行 job        –m yarn-cluster 提交任务到yarn上运行
        ./flink run –m yarn-cluster -c com.liu.wc.StreamWordCount FlinkTutorial-1.0-SNAPSHOT-jar-with-dependencies.jar --host lcoalhost –port 7777