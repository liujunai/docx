4  实时监控目录下的多个追加文件

1．创建配置文件 flume-taildir-hdfs.conf
    创建一个文件
    vim flume-taildir-hdfs.conf
    添加如下内容
    a3.sources = r3
    a3.sinks = k3
    a3.channels = c3

    # Describe/configure the source
    a3.sources.r3.type = TAILDIR
    a3.sources.r3.positionFile = /opt/module/flume/tail_dir.json
    a3.sources.r3.filegroups = f1
    a3.sources.r3.filegroups.f1 = /opt/module/flume/files/file.*

    # Describe the sink
    a3.sinks.k3.type = hdfs
    a3.sinks.k3.hdfs.path =
    hdfs://hadoop102:9000/flume/upload/%Y%m%d/%H
    #上传文件的前缀
    a3.sinks.k3.hdfs.filePrefix = upload-
    #是否按照时间滚动文件夹
    a3.sinks.k3.hdfs.round = true
    #多少时间单位创建一个新的文件夹
    a3.sinks.k3.hdfs.roundValue = 1
    #重新定义时间单位
    a3.sinks.k3.hdfs.roundUnit = hour
    #是否使用本地时间戳
    a3.sinks.k3.hdfs.useLocalTimeStamp = true
    #积攒多少个 Event 才 flush 到 HDFS 一次
    a3.sinks.k3.hdfs.batchSize = 100
    #设置文件类型，可支持压缩
    a3.sinks.k3.hdfs.fileType = DataStream
    #多久生成一个新的文件
    a3.sinks.k3.hdfs.rollInterval = 60
    #设置每个文件的滚动大小大概是 128M
    a3.sinks.k3.hdfs.rollSize = 134217700
    #文件的滚动与 Event 数量无关
    a3.sinks.k3.hdfs.rollCount = 0

    # Use a channel which buffers events in memory
    a3.channels.c3.type = memory
    a3.channels.c3.capacity = 1000
    a3.channels.c3.transactionCapacity = 100

    # Bind the source and sink to the channel
    a3.sources.r3.channels = c3
    a3.sinks.k3.channel = c3

2.启动监控文件夹命令
    bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-taildir-hdfs.conf

3. 向 files 文件夹中追加内容
    在/opt/module/flume 目录下创建 files 文件夹
    mkdir files
    向 upload 文件夹中添加文件
    echo hello >> file1.txt
    echo flume >> file2.txt

