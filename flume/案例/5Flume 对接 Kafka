5  Flume 对接 Kafka

1）配置 flume(flume-kafka.conf)

    a1.sources = r1
    a1.sinks = k1
    a1.channels = c1

    # source
    a1.sources.r1.type = exec
    a1.sources.r1.command = tail -F -c +0 /opt/module/data/flume.log
    a1.sources.r1.shell = /bin/bash -c

    # sink
    a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
    a1.sinks.k1.kafka.bootstrap.servers =
    hadoop102:9092,hadoop103:9092,hadoop104:9092
    a1.sinks.k1.kafka.topic = first
    a1.sinks.k1.kafka.flumeBatchSize = 20
    a1.sinks.k1.kafka.producer.acks = 1
    a1.sinks.k1.kafka.producer.linger.ms = 1

    # channel
    a1.channels.c1.type = memory
    a1.channels.c1.capacity = 1000
    a1.channels.c1.transactionCapacity = 100

    # bind
    a1.sources.r1.channels = c1
    a1.sinks.k1.channel = c1

2） 启动 kafkaIDEA 消费者

3） 进入 flume 根目录下，启动 flume
    $ bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf

4） 向 /opt/module/data/flume.log 里追加数据，查看 kafka 消费者消费情况
    $ echo hello >> /opt/module/data/flume.log